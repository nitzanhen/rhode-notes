{
  "id": "34",
  "name": "מנמ\"א ממן 12",
  "body": "---\nheader-includes:  \\setmonofont{Courier New}\n---\nמצטער על האיחור!\n\n## שאלה 1\n### סעיף א'\n$A$ ערימת מינימום עם $n$ איברים שונים.\nאת האלגוריתם הנדרש `IncreaseKey(i, val)` אפשר לממש באופן הבא:\n``` {.numberLines}\nIncreaseKey(i, val)\n  A[i] ← val\n  MinHeapify(A, i)\n```\n\nכש-`MinHeapify(A,i)` היא הגרסה של `MaxHeapify(A,i)` (פרק 6.2 בספר) עבור ערימת מינימום:\n``` {.numberLines}\nMinHeapify(A,i)\n  l ← Left(i)\n  r ← Right(i)\n  if l ≤ heap-size[A] and A[l] < A[i]\n    smallest ← l\n  else\n    smallest ← i\n  if r ≤ heap-size[A] and A[r] < A[smallest]\n    smallest ← r\n\n  if smallest ≠ i\n    exchange A[i] ↔ A[smallest]\n    MinHeapify(A, smallest)\n```\n\n\n**נכונות**: אחרי ההשמה של $\\operatorname*{val}$ במקום $A[i]$, הערימה מכילה את הערכים הנדרשים, אלא שהערך החדש עשוי להפר את מבנה הערימה. כדי לתקן את ההפרה מחליקים את הערך החדש במורד הערימה: שני הבנים של $i$ הם שורשים של עצים שמקיימים את תכונת הערימה, לכן בסוף הריצה של `MinHeapify` גם האיבר במקום ה-$i$ יהיה שורש של ערימה. האיברים שלפני $i$ לא השתנו, ולכן המערך כולו מקיים את תכונת הערימה.\n\n**סיבוכיות**: בדומה לאלגוריתם `MaxHeapify`, סיבוכיות הזמן של `MinHeapify` במקרה הגרוע היא $\\Theta(\\log n)$, או לחילופין $\\Theta(h)$ כש-$h$ זה גובה האיבר $i$ בערימה; סיבוכיות המקום היא $\\Theta(1)$. `IncreaseKey` מוסיף עליה עוד פעולת השמה אחת, ולכן גם לו יש סיבוכיות זמן $\\Theta(\\log n)$ וסיבוכיות מקום $\\Theta(1)$. $\\square$\n\n### סעיף ב'\nזמן הריצה של הפסודו-קוד הנתון הוא $\\Omega(n)$ כי לולאת ה-for מבצעת $n$ איטרציות שכולן $\\Omega(1)$. לכן מספיק להראות שזמן הריצה הוא $O(n)$, והנימוק דומה מאוד לנימוק שהאלגוריתם `Build-Max-Heap(A)` מפרק 6.3 רץ בזמן לינארי:\nהגובה של ערמה עם $n$ איברים הוא $\\floor{\\log n}$, ומספר הצמתים שגובהם $h$ הוא לכל היותר $\\ceil{n/2^{h+1}}$. כפי שאמרנו בסעיף הקודם, `IncreaseKey(i, val)` רץ בזמן $O(h)$, כש-$h$ זה הגובה של $i$ בערימה. לכן זמן הריצה הכולל הוא\n$$\\sum_{h=0}^{\\floor{\\log n}}{\\ceil{\\frac{n}{2^{h+1}}}}O(h)=O\\left(n\\sum_{h=0}^{\\floor{\\log n}}\\frac{h}{2^{h+1}}\\right)=O(n)$$\nכשהמעבר האחרון נובע מכך ש-\n$$\\sum_{h=0}^{\\floor{\\log n}}\\frac{h}{2^{h+1}}\\le \\sum_{h=0}^{\\infty}\\frac{h}{2^{h+1}}=\\frac{1}{2}\\sum_{h=0}^{\\infty}\\frac{h}{2^{h}}=\\frac{1}{2}\\cdot 2=1$$\nכנדרש. \nזה לא נדרש לסיבוכיות, אבל אפשר אף לדייק יותר את ניתוח זמן הריצה אם נבחין שהבחירה של `MaxVal` בקטע הקוד מקיימת את התכונה הבאה: בתחילת האיטרציה ה-$i$ של לולאת ה-for, ערכו של המשתנה `MaxVal` גדול ממש מכל איבר בערימה (הקביעה הזו שקולה לקביעה שערכו גדול מהמקסימום של האיברים מהערימה, וזו שמורה של לולאת ה-for שבקטע). מכיוון ש-$A$ היא ערימת מינימום, אחרי הגדרת ערכו של האיבר ה-$i$, הוא יוחלק בכל איטרציה עד לתחתית העץ, כלומר יתבצעו בדיוק $h(i)$ החלקות. יחד עם החישוב שלעיל, נקבל שבמהלך ריצת קטע הקוד מתבצעות בקירוב $n$ החלקות (עבור ערכי $n$ גדולים, שבהם הסכום על $h$ מתקרב ל-$1$), כלומר החסם העליון שמצאנו הוא די הדוק (להבדיל מהחסם הראשוני שמצאנו – $n$ איטרציות של $\\Omega(1)$). $\\square$\n\n\\newpage\n\n## שאלה 2\nבהשראת בעיה 6-3 מהספר, נכנה טבלה כפי שמתוארת בשאלה **טבלת יאנג**. בהינתן טבלה $A$ כזו בגודל $m\\times n$, נכנה את $m$ **הגובה** של הטבלה ואת $n$ **הרוחב** שלה – בפסודוקוד, $m=\\operatorname*{height}[A], n=\\operatorname*{width}[A]$.\n\n### סעיף א'\nנדרש לכתוב אלגוריתם שמקבל טבלת יאנג $A$ ומספר $k$, ומחזיר את מקומו בטבלה, או $0$ אם הוא לא נמצא:\n``` {.numberLines}\nSearch-Young(A, k)\n  m ← height[A]\n  n ← width[A]\n  i ← 1\n  j ← n\n  while j ≥ 1 and i ≤ m\n    v ← A[i,j]\n    if v = k\n      return i,j\n    else if v > k\n      j ← j-1  ▷ go left\n    else\n      i ← i+1  ▷ go down\n  return 0  ▷ not found\n\n```\n\n \n(הערה: אם האיבר נמצא בטבלה מוחזר כאן הזוג $i,j$, אבל בהתאם להנחיות אם הוא לא נמצא מוחזר $0$; במימוש אמיתי אולי היה הגיוני לשנות את הערך המוחזר כך שיחזיר את המקום ה\"משוטח\", למשל $mi+j$ במקום הזוג $i,j$, כדי שיתאים לטיפוס הערך $0$, אבל זה לא מהותי לרעיון האלגוריתם)\n\n**נכונות**: נכנה זוג אינדקסים $r,c$ **טוב** אם $A[r,c]=k$. רעיון האלגוריתם דומה לרעיון האלגוריתם החיפוש עם ה\"אצבעות\" מממ\"ן 11 (אלגוריתם ב' בשאלה 3): מתחילים מהפינה הימנית העליונה של הטבלה, ובכל שלב, אם לא נמצא הערך המבוקש, הולכים שמאלה או למטה, עד שמגיעים לקצה הטבלה. בחירת הצעד מנצלת את המיון של הטבלה בשורות והעמודות כדי להבטיח שלא מתפספס זוג אינדקסים טוב; ביתר פירוט, נוכיח ששמורת הלולאה הבאה מתקיימת: \nבתחילת כל איטרציה, אם קיים זוג אינדקסים טוב $r,c$, אז $r\\ge i, c\\le j$.\n- **אתחול**: בתחילת האיטרציה הראשונה מתקיים $i=1,j=n$, ובשל ממדי הטבלה כל מקום $(r,c)$ מקיים $r\\ge 1, c\\le n$.\n- **תחזוקה**: נניח ששמורת הלולאה מתקיימת בתחילת איטרציה מסוימת. אם האיטרציה הסתיימה, אז בפרט מתקיים $A[i,j]\\neq k$. נסמן ב-$i',j'$ את הערכים של $i,j$ בסוף האיטרציה, ונפרק למקרים:\n    - $A[i,j]>k$: אז $j'=j-1,i'=i$. עלינו להראות שאם יש אינדקסים טוב $r,c$ אז $r\\ge i', c\\le j'$ – בשל שמורת הלולאה, זוג אינדקסים כזה בהכרח מקיים $r\\ge i=i', c\\le j=j'+1$, לכן מספיק להראות שאין זוג $r\\ge i,c=j$ שהוא טוב. אבל הטבלה $A$ ממוינת בטורים, לכן לכל $r\\ge i$, \n$$A[r,j]\\ge A[i,j]\\gt k$$\nולכן $r,j$ לא זוג טוב, כנדרש.\n    - $A[i,j]\\lt k$: מוכח באופן אנלוגי למקרה הראשון: במקרה הזה $j'=j,i'=i+1$, ועלינו להראות שאין זוג אינדקסים טוב $r=i,c\\le j$. הטבלה $A$ ממוינת בשורות, לכן לכל $c\\le j$,\n$$A[i,c]\\le A[i,j]\\lt k$$\nולכן הזוג $i,c$ לא זוג טוב.\n- **סיום**: נניח שהלולאה לא סיימה מוקדם, כלומר לא נמצא זוג טוב. אז תנאי הכניסה של הלולאה כבר לא מתקיים, כלומר מתקיים $j=0$ או $i=m+1$; אבל משמורת הלולאה במקרה הזה, אם יש זוג אינדקסים טוב $r,c$ אז $r\\ge i\\gt m$ או $c\\le j\\lt 1$ וזה חורג מגבולות הטבלה, לכן לא אפשרי – כלומר לא קיים זוג כזה. כלומר, אם הלולאה לא מצאה זוג טוב אז לא קיים כזה בטבלה, ולכן האלגורתם תקין גם במקרה זה.\n\nלסיום, עלינו להוכיח שהלולאה אכן מסיימת לרוץ אחרי מספר סופי של צעדים; זה נובע משמורת הלולאה הבאה, שתעזור לנו גם בניתוח הסיבוכיות: בתחילת האיטרציה ה-$k$, מתקיים $i+(n-j)=k+1$. אכן, בתחילת האיטרציה הראשונה מתקיים $i+(n-j)=1+(n-n)=1$; אם זה מתקיים בתחילת האיטרציה ה-$k$, והאיטרציה מסתיימת, אז בסופה $i'=i+1,j'=j$ או $i'=i,j'=j-1$; בכל מקרה $i'+(n-j')=i'+(n-j)+1=k+1$. \n\nמתקיים $i\\le m, j\\ge 1$, ולכן $i+(n-j)\\le m+n-1$; לכן, האלגוריתם מבצע לכל היותר $m+n$ איטרציות, ובפרט הלולאה אכן מסתיימת אחרי מספר סופי של איטרציות.\n\n**סיבוכיות**: כאמור, האלגוריתם מבצע לכל היותר $m+n$ איטרציות, וכל איטרציה היא $\\Theta(1)$, לכן סיבוכיות הזמן של האלגוריתם היא $O(m+n)$. במקרה הגרוע ביותר, החיפוש מגיע לפינה השמאלית התחתונה ואז נכשל (זה מתקיים למשל עבור הטבלה שניתנה כדוגמה בשאלה, עבור $k=31$). במקרה הזה מגיעים לאיטרציה ה-$m+n$, ולכן סיבוכיות הזמן במקרה הגרוע היא $\\Theta(m+n)$.\nהאלגוריתם משתמש בחמישה משתני עזר, לכן סיבוכיות המקום היא $\\Theta(1)$. $\\square$\n\n### סעיף ב'\nנדרש לכתוב אלגוריתם שמקבל טבלת יאנג $A$ ומספר $k$, מכניס אותו במקום האיבר המקסימלי ומסדר את הטבלה מחדש כך שתהיה טבלת יאנג שוב. המימוש שואב השראה מ-`IncreaseKey(i, val)` משאלה 1:\n``` {.numberLines}\nInsert(A,k):\n  A[height[A], width[A]] = k\n  Youngify(A, height[A], width[A])\n```\n  \nכש-`Youngify(A,i,j)` שואב השראה מהאלגוריתם `Max-Heapify(A, i)` מהספר, אלא שהוא מחליק את האיבר במעלה הטבלה במקום למטה:\n``` {.numberLines}\nYoungify(A,i,j)\n  largest ← (i,j)\n  if i > 1 and A[i-1,j] > A[largest]\n    largest ← (i-1,j)\n  if j > 1 and A[i,j-1] > A[largest]\n    largest ← (i,j-1)\n\n  if largest ≠ (i,j)\n    exchange A[largest] ↔ A[i,j]\n    Youngify(A, largest)\n```\n\n\n**נכונות**: נאמר שמקום $(i,j)$ בטבלה מקיים את **תכונת יאנג** אם $A[i,j]\\ge A[i-1,j],A[i,j-1]$ (ככל שאלה מוגדרים). בנוסף, נאמר ש-$(i,j)$ הוא ה**שורש** של הטבלה של כל האינדקסים שנמצאים משמאלו או מעליו, כלומר כל המקומות $(r,c)$ כך ש-$1\\le r\\le i, 1\\le c\\le j$; באופן שקול, נאמר שהטבלה **נפרשת תחת** $(i,j)$. לבסוף, נאמר שהטבלה שנפרשת ע\"י $(i,j)$ מקיימת את תכונת יאנג אם כל מקום בה מקיים אותה.\nנוכיח את הטענה הבאה באינדוקציה על $i+j$: אם כל מקום בטבלה שנפרשת תחת $(i,j)$ מקיימת את תכונת יאנג פרט, אולי, ל-$(i,j)$ עצמו, אז בסוף הריצה של `Youngify` הטבלה מקיימת את תכונת יאנג.\n- $i+j=2$: אז $i=j=1$, והטבלה שנפרשת תחת $(i,j)$ במקרה הזה מכילה רק את $(i,j)$. בפרט, תכונת יאנג מתקיימת באופן ריק.\n- נניח שהוכחנו את הטענה לכל זוג $(i,j)$ שמקיים $i+j\\lt n$, ונניח ש-$i+j=n$. אם $\\operatorname*{largest}=(i,j)$, אז $A[i,j]\\ge A[i-1,j],A[i,j-1]$ (ככל שהם מוגדרים), ולכן הוא מקיים את תכונת יאנג – לכן כל מקום בטבלה שנפרשת תחתיו מקיים אותה, כלומר הטבלה מקיימת את תכונת יאנג.\nאחרת,  $\\operatorname*{largest}=(i',j')$ הוא אחד מבין הזוגות $(i-1,j),(i,j-1)$. לפני הקריאה הרקורסיבית, $A[\\operatorname*{largest}]$ מוחלף עם $A[i,j]$, ומהגדרת $\\operatorname*{largest}$ נובע שאחרי החלפה, המקום $(i,j)$ מקיים את תכונת יאנג, ומנגד ייתכן שעתה המקום $\\operatorname*{largest}$ לא מקיים אותה. אבל שתי האפשרויות עבור $\\operatorname*{largest}$ מקיימות $i'+j'=n-1$, וכעת $\\operatorname*{largest}$ מקיים את תנאי הטענה; לכן בסוף הקריאה הרקורסיבית הטבלה שנפרשת תחתיו מקיימת את תכונת יאנג, ולכן גם הטבלה שנפרשת תחת $(i,j)$ מקיימת אותה.\n\n**סיבוכיות**: פרט לקריאה הרקורסיבית, זמן הריצה $T(i,j)$ של `Youngify` חסום ע\"י קבוע $C$. נוכיח באידוקציה ש-$T(i,j)=O(i+j)$:\n- $i+j=2$: אז $i=j=1$ בהכרח. במקרה הזה בהכרח $\\operatorname*{largest}=(1,1)$, ו-$T(1,1)\\le C\\lt 2C$.\n- נניח שהוכחנו את הטענה לכל זוג $i,j$ שמקיים $i+j\\lt n$, ונניח ש-$i+j=n$. אם $\\operatorname*{largest}=(i,j)$, אז $T(i,j)\\le C$. אחרת, $\\operatorname*{largest}=(i',j')$ הוא אחד מבין הזוגות $(i-1,j),(i,j-1)$. עבור שתי האפשרויות מתקיים $i'+j'=i+j-1$, ומהנחת האינדוקציה נסיק ש-\n$$T(i,j)\\le C+T(i',j')\\le C+C(i+j-1)=C(i+j)$$\nובכל מקרה מתקיים $T(i,j)\\le C(i+j)$, כנדרש.\nבדומה ל-`MaxHeapify`, במקרה הגרוע – שבו $A[i,j]\\lt A[r,c]$ לכל $1\\le r\\le i,1\\le c\\le j$, יתבצעו $i+j$ קריאות רקורסיביות, ולכן במקרה הגרוע סיבוכיות הזמן היא $\\Theta(i+j)$.\n\nהפונקציה `Insert` מבצעת השמה אחת ואז קוראת ל-`Youngify(A,m,n)`, לכן סיבוכיות הזמן שלה היא $\\Theta(m+n)$.\nסיבוכיות המקום של האלגוריתם, פרט לקריאה הרקורסיבית, היא $\\Theta(1)$; כאמור במקרה הגרוע מתבצעות $m+n$ קריאות רקורסיביות, לכן סיבוכיות המקום במקרה הגרוע היא $\\Theta(m+n)$. כדי להקטין אותה ל-$\\Theta(1)$, אפשר לשנות את `Youngify` לגרסה איטרטיבית:\n``` {.numberLines}\nYoungifyIterative(A)\n  i ← height[A]\n  j ← width[A]\n\n  largest ← (i,j)\n  do\n    exchange A[largest] ↔ A[i,j]\n    (i,j) ← largest\n    if i > 1 and A[i-1,j] > A[largest]\n      largest ← (i-1,j)\n    if j > 1 and A[i,j-1] > A[largest]\n      largest ← (i,j-1)\n  while largest ≠ (i,j)\n```\n\n\n(את השימוש ב-do-while אפשר להחליף בלולאת while רגילה, אם מעתיקים את שני בלוקי ה-if ומוסיפים אותם מתחת להגדרה הראשונית של `largest`, אך זה פחות אלגנטי לדעתי).\nתוכן האלגוריתם וניתוח הנכונות והסיבוכיות תקפים משיקולים דומים למקרה הרקורסיבי, עם השינויים המתחייבים (הוכחה בעזרת שמורת לולאה במקום אינדוקיה, למשל). \n\n\n### סעיף ג'\nנדרש לכתוב אלגוריתם שמקבל כקלט טבלת יאנג $A$ ומספר $k$, ומחזיר את $k$ האיברים הקטנים ביותר בטבלה.\nרעיון האלגוריתם הוא כזה: משתמשים בתור קדימויות $Q$ עם קיבולת $k$ (כלומר, ערימת מינימום שנשענת על מערך בגודל $k$), שהאיברים בו הם מקומות $(i,j)$ בטבלה, והמפתח של כל איבר יהיה $A[i,j]$. בשלב ראשון, התור מכיל רק את הפינה השמאלית העליונה (שבה נמצא הערך המינימלי בטבלה). אחר כך, מבצעים $k$ פעמים את הפעולות הבאות: מחלצים את המינימום מ-$Q$, שבאיטרציה ה-$l$ מצביע על האיבר ה-$l$ הכי קטן בטבלה, ופולטים אותו. במקומו, מכניסים לטבלה את שני הצמתים מימין למינימום ומתחתיו, כך ש-$Q$ מכיל את כל המועמדים להיות האיבר ה-$l+1$ הקטן ביותר בטבלה. \n\nלבסוף, בשל העובדה שלכל איבר בטבלה יש יותר מ\"מסלול\" אחד שמוביל אליו, עשוי להיווצר מצב שאיבר מוכנס פעמיים לתור הקדימויות. כדי למנוע זאת, נניח שלכל איבר בטבלה יש שדה בוליאני `searched` שניתן לעריכה (לפי שאלה שנשאלה בפורום של מטלה 2, מותר להניח זאת). כשמוסיפים איבר לתור מסמנים אותו, וכך כל איבר נסרק פעם אחת לכל היותר (באופן שמזכיר סריקת BFS בגרף).\n\n``` {.numberLines}\nFindSmallest(A, k)\n  create min heap Q[1..2k]\n  Insert(Q, (1, 1), A[1, 1])\n  searched[A[1, 1]] ← true\n\n  for l ← 1 to k\n    (i,j) ← ExtractMin(Q)\n    output (i,j)\n\n    ▷ Add children to Q\n    if i < height[A] and searched[A[i+1, j]] = false\n      Insert(Q, (i+1, j), A[i+1, j])\n    if j < width[A] and searched[A[i, j+1]] = false\n      Insert(Q, (i,j+1), A[i,j+1])\n```\n\n\n(הערה: ב-output הכוונה \"להכריז\" על הערך ככזה שמקיים את מה שמחפשים. במימוש אמיתי אפשר היה, נניח, ליצור רשימה או מבנה נתונים אחר ולהוסיף אותם אליו כשמוצאים, ובסוף להחזיר את הרשימה כולה, אבל זה לא מהותי לרעיון האלגוריתם).\n\nהפונקציות `Insert` ו-`ExtractMin` כאן טיפה שונות בסמנטיקה מאלה שמופיעות בספר (אבל מהותית הן שקולות):\n- `Insert(Q, x, key)` מכניסה את האיבר $x$ לתור $Q$ עם המפתח $\\operatorname*{key}$. סיבוכיות הזמן שלו היא $O(\\log k)$, והיא מתקבלת במקרה הגרוע (כלומר החסם הדוק).\n- `ExtractMin(Q)` מוציא ומחזיר את המינימום מ-$Q$. גם סיבוכיות הזמן שלו היא $O(\\log k)$. במקרה הגרוע, שבו הערימה $Q$ ממוינת (להבדיל מקיום תכונת הערימה בלבד), סיבוכיות הזמן של `ExtractMin` היא $\\Theta(\\log k)$, שכן זו שמה את האיבר האחרון – המקסימלי – בראש הערימה, ולכן הקריאה שלו ל-`MinHeapify` תדרוש $\\log k$ החלקות. \n\nנשים לב בכל איטרציה, איבר אחד יוצא מהתור ומוכנסים לכל היותר שניים; לכן בסוף האיטרציה ה-$l$ יש לכל היותר $l$ איברים בתור, והוא אף פעם לא מתמלא.\n\nסיבוכיות הזמן של בניית התור לוקחת $\\Theta(1)$ (בגלל שהאיבר שמוכנס הוא הראשון, מתקיים $\\operatorname*{heap-size}(Q)=1$ ולכן ההכנסה מתבצעת בזמן קבוע). כל איטרציה בלולאה היא $O(\\log k)$, כי זו הסיבוכיות של `ExtractMin` ושל `Insert`. לכן סיבוכיות הזמן הכוללת היא $O(k\\log k)$.\nבמקרה הגרוע ביותר, התור $Q$ שנוצר נשאר ממוין לאורך כל ריצת האלגוריתם, ואז כל איטרציה לוקחת $\\Theta(\\log k)$, כלומר סיבוכיות הזמן במקרה הגרוע היא $\\Theta(k\\log k)$.\n\nסיבוכיות המקום היא $\\Theta(\\log k)$, שכן פרט למשתני עזר האלגוריתם משתמש רק בתור $Q$, והקיבולת שלו היא $k$. $\\square$\n\n\\newpage\n\n## שאלה 3\nלאורך השאלה, כדי לציין שמערך $A$ כמעט ממוין עם שגיאה בגודל $k$ נאמר גם ש-$A$ ממוין עד כדי שגיאה בגודל $k$, או ש-$A$ $k$-כמעט-ממוין.\n\n### סעיף א'\nבאלגוריתם המקורי של מיון מהיר `Quicksort(A,p,r)`, תנאי העצירה של הרקורסיה הוא ש-$r\\le p$, כלומר שהפרוסה מתוך המערך שיש למיין ריקה; אם נשנה את התנאי כך שהרקורסיה תעצור כשגודל הפרוסה קטן מ-$k$, האלגוריתם ימיין את המערך רק עד כדי שגיאה בגודל $k$:\n``` {.numberLines}\nAlmostQuicksort(A, p, r):\n  if r-p ≥ k:\n    q ← Partition(A,p,r)\n    Quicksort(A, p, q-1)\n    Quicksort(A, p, q+1)\n```\n\n\n(`Partition` היא אלגוריתם החלוקה כמו שהוצג בספר). נוכיח שהאלגוריתם פועל כנדרש באינדוקציה על גודל המערך, $n$:\n- אם $n\\le k$, אז  במקרה הזה `AlmostQuicksort` לא עושה כלום, אבל מנגד אין $1\\le i,j\\le n$ שמקיימים $j-i\\gt k$, כלומר התנאי מתקיים באופן ריק ו-$A$ כבר ממוין עד כדי שגיאה בגודל $k$.\n- יהי $n\\gt k$, ונניח שהוכחנו את הטענה לכל $m\\lt n$. הפונקציה `Partition` משנה את המערך ומחזירה אינדקס $q$ כך שלכל $i\\le q\\le j$ מתקיים $A[i]\\le A[q]\\le A[j]$, ומהנחת האינדוקציה המיון ממיין את הפרוסות $A[1..q-1],A[q+1..n]$ עד כדי שגיאה בגודל $k$. \nנניח ש-$i\\lt j$ אינדקסים שעבורם מתקיים $A[i]\\gt A[j]$, אחרי המיון. לא ייתכן ש-$i\\le q\\le j$ – שכן אחרת כאמור $A[i]\\le A[q]\\le A[j]$ – לכן בהכרח מתקיים $i\\lt j\\le q$ או $q\\le i\\lt j$, כלומר $i,j$ שייכים לאותה פרוסה. אבל הפרוסות $A[1..q-1],A[q+1..n]$ שתיהן ממוינות עד כדי שגיאה בגודל $k$, לכן בהכרח $j-i\\le k$.\nאם כן, המערך כולו ממוין עד כדי שגיאה בגודל $k$.\n\nנמצא את הסיבוכיות של `AlmostQuicksort` במקרה הטוב ובמקרה הגרוע: \nההבדל העיקרי מהניתוח בספר הוא שכאן הסיבוכיות של $T(n)$, עבור $n\\le k$, קבועה.\nבמקרה הגרוע, כפי שמוסבר בספר, החלוקה יוצרת בכל שלב פרוסה אחת ריקה ופרוסה אחת שמכילה איבר אחד פחות, כלומר מתקבלת נוסחת הנסיגה\n$$T(n)=T(n-1)+f(n)$$\nכש-$f(n)=\\Theta(n)$ היא סיבוכיות הזמן של `Partition`. באינדוקציה נקבל שלכל $i$ \"קטן\",\n$$T(n)=T(n-i)+\\sum_{j=0}^{i}f(n-j)$$\nאת האינדוקציה נמשיך עד ש-$n-i=k$, כלומר $i=n-k$, ואז נקבל\n$$T(n)=T(k)+\\sum_{j=0}^{n-k}f(n-j)=\\Theta(1)+\\sum_{j=k}^nf(j)$$\nמתקיים $f(n)=\\Theta(n)$, לכן יש קבועים $c_1,c_2\\gt 0$ ו-$n_0$ שהחל ממנו, $c_1n\\le f(n)\\le c_2$. בה\"כ $k\\ge n_0$ – אחרת נפצל את הסכום\n$$\\sum_{j=k}^nf(j)=\\sum_{j=k}^{n_0}f(j)+\\sum_{j=n_0+1}^nf(j)$$\nוהמחובר הראשון מימין הוא קבוע (לא תלוי ב-$n$), לכן למחובר הימני אותו סדר גודל כמו הסכום המקורי. אם כן, נרשום\n$$c_1\\sum_{j=k}^nj\\le \\sum_{j=k}^nf(j)\\le c_2\\sum_{j=k}^nj$$\nו-\n$$2\\sum_{j=k}^nj=2\\sum_{j=1}^nj-2\\sum_{j=1}^kj=n(n+1)-k(k+1)=n^2-k^2+n-k=\\Theta(n^2-k^2)$$\nכשהמעבר האחרון מסתמך על כך ש-$n^2-k^2=(n+k)(n-k)\\ge n-k$ ו-$\\Theta(f+g)=\\Theta(\\max(f, g))$. לכן\n$$T(n)=\\Theta\\left(\\sum_{j=k}^nf(j)\\right)=\\Theta\\left(\\sum_{j=k}^nj\\right)=\\Theta(n^2-k^2)$$\n\nבמקרה הטוב, החלוקה יוצרת בכל שלב פרוסות מאוזנות ככל שניתן, כלומר אחת בגודל $\\floor{\\frac{n}{2}}$ ואחת בגודל $\\ceil{\\frac{n}{2}}-1$. ערכי הרצפה והתקרה, כמו גם ההזזה ב-$1$, לא משפיעים על סיבוכיות הבעיה, ולכן נוכל למצוא אותה ע\"י נוסחת הנסיגה\n$$T(n)=2T(n/2)+f(n)$$\nכש-$f(n)=\\Theta(n)$ כמו מקודם. כעת נקבל באינדוקציה\n$$T(n)=2^iT\\left(\\frac{n}{2^i}\\right)+\\sum_{j=0}^i{2^jf\\left(\\frac{n}{2^j}\\right)}$$\nאת האינדוקציה אפשר להמשיך כל עוד $n/2^i\\gt k$, כלומר עד ש-\n$$\\frac{n}{2^{i+1}}\\le k\\Longleftrightarrow i+1\\ge \\log\\left(\\frac{n}{k}\\right)$$\nכלומר עד $i=\\ceil{\\log(n/k)}$. כמו מקודם, ערך התקרה לא משנים את סדר הגודל, לכן אפשר להתעלם ממנו. בנוסף, כמו מקודם, אפשר להניח בה\"כ ש-$k\\ge n_0$, לכן $c_1n \\le 2^if(n/2^i)\\le c_2n$ ולכן\n$$c_1(i+1)n\\le\\sum_{j=0}^i{2^jf\\left(\\frac{n}{2^j}\\right)}\\le c_2(i+1)n$$\nיחד נקבל\n$$T(n)=2^{\\log(n/k)}T\\left(\\frac{n}{2^{\\log(n/k)}}\\right)+\\sum_{j=0}^i{2^jf\\left(\\frac{n}{2^j}\\right)}=\\frac{n}{k}\\Theta(1)+\\Theta\\left(\\left(\\log(n/k)+1\\right)n\\right)=\\Theta(n\\log(n/k))$$\nכשמעבר האחרון השתמשנו בכך ש-$n/k\\le n\\le n\\log(n/k)$ וש-$\\Theta(f+g)=\\Theta(\\max(f, g))$. $\\square$\n\n### סעיף ב'\nעבור מיון הכנסה על מערך $k$-כמעט ממוין, המקרה הטוב הוא שהמערך כבר ממוין – בדיוק כמו עבור מערך כללי – וזמן הריצה האסימפטוטי במקרה הזה הוא $\\Theta(n)$. היתרון של מיון עד כדי שגיאה בגודל $k$ בא לידי ביטוי במקרה הגרוע: \n\nנוכיח שאם המערך $A$ הוא $k$-כמעט-ממוין בתחילת האיטרציה של הלולאה החיצונית של מיון הכנסה (אני עובד מול הפסודו-קוד `(A)Insertion-Sort` שמופיע בפרק 2.1 בספר) אז הוא כזה גם בסופה: יהיו $i, j$ אינדקסים שמקיימים $j-i>k$. אז $A[i]\\le A[j]$ בתחילת האיטרציה, ועלינו להראות שזה מתקיים גם בסופה. \nנניח שאנחנו באיטרציה ה-$l$. \n- משמורת הלולאה של מיון הכנסה שמוצגת בפרק 2.2, בסוף האיטרציה הפרוסה $A[1..l]$ ממוינת, לכן אם $j\\le l$ אז $i\\lt j\\le l$ בחלק הממוין ולכן $A[i]\\le A[j]$.\n- בנוסף, במהלך האיטרציה ה-$l$ רק הפרוסה $A[1..l]$ משתנה, כלומר אם $i\\ge l+1$ אז האיברים $A[i],A[j]$ לא משתנים, ולכן $A[i]\\le A[j]$.\n- לכן, נניח ש-$i\\le l$ ו-$j\\gt l$. אז $A[j]$ לא משתנה במהלך האיטרציה, ו-$A[i]$ עשוי להשתנות. אם הוא לא משתנה, מובן שעדיין מתקיים $A[i]\\le A[j]$. אם הוא כן משתנה, זה יכול לקרות בשתי דרכים: או ש-$A[i]\\leftarrow A[i-1]$, זאת במקרה ש-$i=l$, כלומר $A[i]$ מוכנס למערך והוא לא מקסימלי; או ש-$A[i]\\leftarrow A[l]$, זאת כשהאיבר החדש מוכנס במקום ה-$i$. במקרה הראשון מתקיים $A[i-1]\\le A[i]\\le A[j]$ כי הפרוסה $A[1..l]$ ממוינת, וגם במקרה השני מתקיים $A[l]\\le A[i]\\le A[j]$ (אחרת האיבר ה-$l$ לא היה מוכנס לפני האיבר ה-$i$).\nבכל מקרה, מתקיים $A[i]\\le A[j]$ גם בסוף האיטרציה, לכן המערך נשאר $k$-כמעט-ממוין.\n\nנשתמש בשמורת הלולאה הזו כדי להראות שסיבוכיות הזמן של המיון במקרה הגרוע היא $\\Theta(nk)$:\nבכיוון אחד, נתבונן באיטרציה ה-$l$. מתנאי הכניסה של לולאת ה-while נסיק, שהיא ממשיכה עד שנמצא אינדקס $i\\lt l$ עם $A[i]\\le A[l]$ (או עד ש-$i=0$, אם לא נמצא כזה). אבל מהטענה שהוכחנו נסיק שבאיטרציה הזו המערך הוא $k$-כמעט-ממוין, לכן בהכרח מתקיים $A[l-(k+1)]\\le A[l]$ (כי ההפרש ביניהם גדול מ-$k$), ולכן הלולאה הפנימית מבצעת לכל היותר $k$ איטרציות. שאר התוכן של איטרציה של הלולאה החיצונית הוא $\\Theta(1)$ והיא מבצעת $n-1$ איטרציות, לכן נסיק שזמן הריצה הכולל במקרה הגרוע הוא $O(nk)$.\n\nבאשר לחסם תחתון, נשים לב שמערך שממוין בסדר יורד (שזה המקרה הכללי הגרוע ביותר עבור מיון הכנסה) אינו $k$-כמעט-ממוין, עבור $k\\lt n$. מצד שני, לא נתקשה למצוא דוגמא שזמן הריצה שלה הוא $\\Omega(nk)$: \nנרשום $n=qk+r$ חלוקה עם שארית, ונניח שהמערך מורכב מ-$q+1$ סדרות יורדות, כל אחת באורך $k$ (חוץ מהאחרונה שהיא באורך $r$), ושכל איבריה של כל סדרה קטנים ממש מכל איבריה של הסדרה שבאה אחריה. \nבדוגמה זו, באיטרציה ה-$ak+b$ הלולאה הפנימית תבצע בדיוק $b-1$ איטרציות, כי $A[ak+b]\\le A[ak+c]$ לכל $1\\le c\\le b$ אבל $A[ak+b]\\gt A[i]$ לכל $i\\lt ak+1$. \nלכן, אם נתעלם מהאיטרציות של השארית, זמן הריצה של האלגוריתם במקרה הזה יהיה\n$$T(n)\\ge q\\sum_{i=1}^k(i-1)=q\\sum_{i=1}^{k-1}=q\\frac{k(k-1)}{2}=\\frac{1}{2}(n-r)(k-1)=\\Omega(nk)$$\n($r$ אינו קבוע, אבל הוא חסום ע\"י $k$, לכן אחרי פתיחת הסוגריים כל הגורמים יהיו זניחים ביחס ל-$nk$).\nלכן, במקרה הגרוע ביותר זמן הריצה יהיה לפחות $T(n)$, כלומר $\\Omega(nk)$. יחד נקבל שבמקרה הגרוע זמן הריצה הוא $\\Theta(nk)$, כנדרש. $\\square$\n\n### סעיף ג'\nנדרש לכתוב אלגוריתם שממיין מערך $k$-כמעט-ממוין בעזרת ערימה:\n``` {.numberLines}\nHeapAlmostSort(A)\n  ▷ Build a min heap with values A[1],...,A[k]\n  Create array h[1..k]\n  for i ← 1 to k\n    h[i] ← A[i]\n  BuildMinHeap(h)\n\n  ▷ Main loop\n  for i ← 1 to n-k\n    A[i] ← Min(h)\n    IncreaseKey(h, 1, A[i+k])\n\n  ▷ Add the remaining elements in order\n  for i ← n-k+1 to n\n    A[i] ← ExtractMin(h)\n```\n\n\n(הפונקציות `(h)BuildMinHeap` ו-`ExtractMin(h)` הן המקבילות של פעולות הערימה `ExtractMax`, `BuildMaxHeap` שהוצגו בספר עבור ערימת מינימום; `IncreaseKey(A,i,val)` הוא האלגוריתם שהוגדר בשאלה 1).\n\nלפני שננתח את האלגוריתם, נסמן ב-$a_i$ את האיבר ה-$i$ הכי קטן במערך. נשים לב שבגלל שהמערך $k$-כמעט-ממוין, $a_i$ נמצא בפרוסה $A[1..i+k-1]$, שכן לכל $j\\ge i+k$, כל האיברים $A[1],...,A[j-k]$ קטנים או שווים ל-$A[j]$, ויש לפחות $i$ כאלה. \nרעיון האלגוריתם הוא אפוא לבנות ערימת מינימום של $k$ האיברים הראשונים, שהמינימום שלה יהיה כמובן האיבר הקטן במערך. בכל איטרציה בלולאה המרכזית שמים את המינימום בערימה, שהוא בדיוק $a_i$, במקום המתאים, ובמקומו מכניסים לערימה את האיבר ה-$i+k$, כך שהיא בוודאות תכיל את $a_{i+1}$. בשלב מסוים לקראת הסוף נגמרים האיברים לשים בערימה, ואז נותר רק לחלץ את האיברים מהערימה למקומות שנותרו במערך.\n\n**נכונות**: נוכיח את שמורת הלולאה הבאה עבור הלולאה המרכזית: בתחילת האיטרציה ה-$i$, \n1. תת המערך $A[1..i-1]$ ממוין ומכיל את $a_1,...,a_{i-1}$\n2.  כל איבר בפרוסה $A[1..i+k-1]$ נמצא או בפרוסה $A[1..i-1]$ או ב-$h$, ולא בשניהם.\n\n- **אתחול**: באיטרציה הראשונה, תת המערך $A[1..0]$ ריק, לכן $(1)$ מתקיים באופן ריק. בנוסף, הערימה $h$ מאותחלת לפני הלולאה עם הערכים $A[1..k]$, לכן $(2)$ מתקיים.\n- **תחזוקה**: נניח ששמורת הלולאה מתקיימת בתחילת האיטרציה ה-$i$. אז תת המערך $A[1..i-1]$ ממוין ומכיל את $a_1,...,a_{i-1}$. בפרט, $a_i$ לא נמצא ב-$A[1..i-1]$, אבל מצד שני הוא כן נמצא בפרוסה $A[1..i+k-1]$ לפי הטענה שהראנו לעיל, לכן הוא בהכרח נמצא ב-$h$. יותר מכך, הוא בהכרח נמצא בראשה, שכן אחרת בראשה יש איבר קטן ממנו, וכל האיברים שקטנים ממנו כבר אינם בערימה (הם ממלאים בדיוק את הפרוסה $A[1..i-1]$). אז הפעולה $\\operatorname*{Min}(h)$ נותנת לנו את $a_i$, והוא מושם במקומו המתאים ($A[i]$), לכן $(1)$ מתקיים. בשורה הבאה האיבר $A[i+k]$ מוכנס לערימה במקום $a_i$. אז $a_1,...,a_i$ נמצאים כולם במקומות $1,...,i$ בהתאמה, וכל שאר האיברים של הפרוסה $A[1..i+k]$ נמצאים בערימה $h$, לכן גם $(2)$ מתקיים.\n- **סיום**: בסיום הלולאה מתקיים $i=n-k+1$, לכן משמורת הלולאה מתקיים:\n  1. תת המערך $A[1..n-k]$ ממוין ומכיל את $a_1,...,a_{n-k}$\n  2. כל איבר ב-$A[1..n]=A$ נמצא או ב-$A[1..n-k]$ או ב-$h$, ולא בשניהם.\n  מכך נסיק שהאיברים שנותרו בערימה הם בדיוק $a_{n-k+1},...,a_n$, ונותר לשבץ אותם במקומות $A[n-k+i],...,A[n]$ לפי הסדר; הפעולה `ExtractMin(h)` בלולאה האחרונה מוציאה בכל שלב את הקטן שבהם ושמה אותו במקום. לכן, בסופה מתקיים $A[i]=a_i$ לכל $1\\le i\\le n$, כנדרש.\n\n\n**סיבוכיות**: נפרק את חישוב סיבוכיות הזמן לשלבים:\n1. בחלק הראשון, יצירת המערך עם הערכים הנדרשים לוקח $\\Theta(k)$, ו-$\\operatorname*{BuildMinHeap}(h)$ גם רץ בזמן לינארי עם גודל הערימה, כלומר $\\Theta(k)$. יחד, סיבוכיות הזמן של החלק הראשון היא $\\Theta(k)$.\n2. הלולאה המרכזית עוברת $n-k$ איטרציות. `IncreaseKey` רצה בזמן $\\Theta(\\log k)$ במקרה הגרוע, לכן סיבוכיות הזמן של הלולאה היא $\\Theta((n-k)\\log k)$.\n3. גם הסיבוכיות של `ExtractMin` היא $\\Theta(\\log k)$ במקרה הגרוע, לכן סיבוכיות הזמן של הלולאה האחרונה היא $\\Theta(k\\log k)$.\n\nביחד, הלולאה השנייה והשלישית מבצעות $n$ איטרציות של $\\Theta(\\log k)$ במקרה הגרוע, והחלק הראשון רץ בזמן $\\Theta(k)$. מתקיים $k<n<n\\log k$, לכן זמן הריצה הכולל הוא\n$$\\Theta(k+n\\log k)=\\Theta(n\\log k)$$\nסיבוכיות המקום של האלגוריתם היא $\\Theta(k)$, שכן הפעולה משתמשת בערימה בגודל $k$. $\\square$\n\n\\newpage\n\n## שאלה 4\n### סעיף א'\n$A$ מערך באורך $n$ של מספרים ממשיים.\n**מ.ש.ל.** ב-$A$ יש לכל היותר שלושה מספרים שמופיעים במערך יותר מ-$\\floor{n/4}$ פעמים.\n_הוכחה._ נניח בשלילה שיש ארבעה מספרים $a_1,a_2,a_3,a_4$ שחוזרים על עצמם יותר מ-$\\floor{n/4}$ פעמים. אז כל אחד מופיע לפחות $\\floor{n/4}+1\\gt n/4$ פעמים, ומספר ההופעות הכולל של ארבעת הוא לפחות\n$$4\\left(\\floor{\\frac{n}{4}}+1\\right)\\gt 4\\left(\\frac{n}{4}\\right)=n$$\nבסתירה לכך שמספר ההופעות הכולל של כולם הוא לכל היותר מספר האיברים במערך. מהסתירה נסיק שיש לכל היותר שלושה מספרים כאלה. $\\square$\n\n### סעיף ב'\nנדרש לכתוב אלגוריתם שמוצא את כל המספרים שמופיעים במערך $A$ יותר מ-$\\floor{n/4}$ פעמים.\nרעיון האלגוריתם `FindFrequent4(A)` הוא כזה: נסמן ב-$a_1\\le a_2\\le ...\\le a_n$ את איברי המערך $A$, ממוינים. בהשראת תרגיל 9.3-6 בספר, נתבונן בשלושת הקוונטילים מסדר $4$ של קבוצת האיברים של $A$ – במקרה שלנו, $a_{\\floor{n/4}},a_{\\floor{n/2}},a_{\\floor{3n/4}}$. אם איבר $b$ מופיע במערך יותר מ-$\\floor{n/4}$ פעמים, אז יש אינדקים $i,j$ כך ש-$j\\gt i+\\floor{n/4}$ ו-$a_i=a_{i+1}=...=a_j$. אבל בגלל שהמרחק בין $i,j$ גדול יותר מהמרחק בין הקוונטילים, בהכרח אחד מהאינדקסים בין $i$ ל-$j$ שייך לאחד הקוונטילים.\nאת הערך של שלושת הקוונטילים אפשר למצוא בזמן לינארי ע\"י שלוש קריאות ל-`Select` מפרק 9.3, ועבור כל אחד אפשר לסרוק את המערך באופן \"נאיבי\", כלומר לעבור איבר-איבר ולספור את כמות ההופעות שלו:\n``` {.numberLines}\nFindFrequent4(A)\n  n ← length[A]\n  for i ← 1 to 3:\n    quant ← Select(A, floor(in/4))\n    count ← Count(A, quant)\n    if count > floor(n/4)\n      output quant\n```\n\n\n(הערה: ב-output הכוונה \"להכריז\" על הערך ככזה שמקיים את מה שמחפשים. במימוש אמיתי אפשר היה, נניח, ליצור רשימה או מבנה נתונים אחר ולהוסיף אותם אליו כשמוצאים, ובסוף להחזיר את הרשימה כולה, אבל זה לא מהותי לרעיון האלגוריתם).\n\nהאלגוריתם `Count(A, x)` מממש ספירה נאיבית:\n``` {.numberLines}\nCount(A, x)\n  count ← 0\n  for i ← 1 to length[A]\n    if A[i] = x\n      count ← count + 1\n  return count \n```\n\n\nסיבוכיות הזמן של `Select` ושל `Count` היא לינארית, ולולאת ה-for ב-`FindFrquent4` מריצה שלוש איטרציות של כל אחת סה\"כ, לכן זמן הריצה הוא אכן לינארי. \nסיבוכיות המקום היא $\\Theta(1)$. $\\square$\n\n\\newpage\n\n### סעיף ג'\nנדרש אלגוריתם `FindFrequent` שמוצא את כל האיברים ב-$A$ שמופיעים יותר מ-$\\floor{n/k}$ פעמים. הרעיון הוא כזה: \nמקרה הבסיס של הרקורסיה הוא המקרה $k\\le 4$, שבו אפשר לקרוא ל-`FindFrequent4` או לגרסה מקבילה שלה עבור $k=2,3$ (במקרה $k=1$ אין איברים שנמצאים יותר מ-$n$ פעמים, לכן הפונקציה לא פולטת כלום); נניח ש-`FindFrequentBase(A,k)` מקבלת מערך וערך $k\\le 4$, ומטפלת במקרה הזה (בזמן לינארי).\n\nבמקרה הכללי, נניח ש-$b$ ערך שמופיע במערך יותר מ-$\\floor{n/k}$ פעמים; בגלל שמספר ההופעות הוא שלם, זה שקול לכך ש-$b$ מופיע במערך יותר מ-$n/k$ פעמים.\nייתכן שערך החציון מופיע יותר מ-$n/k$ פעמים, לכן נמצא את ערך החציון בעזרת `Select` ונספור נאיבית את כמות ההופעות שלו. עבור כל ערך $b$ אחר, נשים לב שהחלוקה שניתנת ע\"י `Partition`, סביב ערך החציון, תשים את כל ההופעות שלו באחת משני תתי המערכים הנוצרים (השמאלי אם $b$ קטן מהחציון, הימני אחרת). נסמן ב-$q$ את אינדקס החלוקה, אז מתקבלות שתי פרוסות $A[1..q-1],A[q+1..n]$, שכל אחד מהערכים המבוקשים (פרט, אולי לחציון, שאותו כבר בדקנו) נמצא בדיוק באחת מהן. \nתהי $B$ פרוסה באורך $m$, שכל ההופעות של $b$ נמצאות בה. נרשום $n/k=mn/mk=m/\\left(\\frac{m}{n}k\\right)$, ובהתאם נסמן $k':=\\frac{m}{n}k$ (לא בהכרח שלם). אז $b$ מופיע ב-$A$ יותר מ-$n/k$ פעמים אם ורק אם הוא מופיע יותר מ-$m/k'$ פעמים. קריאה רקורסיבית ל-`FindFrequent` עם גבולות הפרוסות והערכים $k'$ המתאימים יניבו לנו את האיברים המבוקשים.\n\nבפסודוקוד שלהלן, נניח שיש בידינו גרסאות של `FindFrequentBase`, `Select` ו-`Count` שמקבלות גם זוג אינדקסים $p,r$ ופועלות רק על הפרוסה $A[p..r]$.\n``` {.numberLines}\nFindFrequent(A,k,p,r)\n  if k ≤ 4\n    return FindFrequentBase(A,k,p,r)\n\n  n ← r-p+1\n  median ← Select(A, floor(n/2), p, r)\n  c ← Count(A, median, p, r)\n  if c > ⌊n/k⌋\n    output median\n\n  ▷ Partition and search subarrays\n  q ← Partition(A, p, r, median)\n  k1 ← (q-p)/n * k\n  FindFrquent(A, k1, p, q-1)\n  k2 ← (r-q)/n * k\n  FindFrquent(A, k2, q+1, r)\n```\nוהקריאה החיצונית ל-`FindFrquent` היא\n``` {.numberLines}\nFindFrquent(A, k)\n  FindFrquent(A, k, 1, n)\n```\n\n\nבאשר לסיבוכיות הזמן, השיטות `Count`,`Select` ו-`Partition` כולן רצות בזמן לינארי על גודל הפרוסה $A[p..r]$, ו-`Partition` מחלקת את המערך לשתי פרוסות כמעט שוות בגודל $\\floor{n/2}, \\ceil{n/2}-1$. ערכי הרצפה והתקרה, כמו גם ההזזה ב-1, לא משנות את סדר הגודל האסימפטוטמי של זמן הריצה, לכן סיבוכיות הזמן נתונה ע\"י פתרון נוסחת הנסיגה\n$$T(n, k)=2T\\left(\\frac{n}{2}, \\frac{k}{2}\\right)+\\Theta(n)$$\nמכאן נמשיך כמו בפתרון שאלה 9.3-6 בספר (או ו'-13 במדריך), שבה מתקבלת הנוסחה הזו בדיוק: נבנה את עץ הרקורסיה. גובה העץ הוא המספר המינימלי $i$ כך ש-$k/2^i\\le 4$, או באופן שקול $i=\\ceil{ \\log (k)-2}$, לכן גובה העץ הוא $\\Theta(\\log k)$.\nברמה ה-$d$ יש לכל היותר $2^d$ צמתים, והעלות של כל צומת בה היא $\\Theta(n/2^d)$, לכן העלות של כל רמה היא $O(n)$, והחסם העליון הזה אכן מתקבל, למשל כשהעץ מלא. \nלכן, במקרה הגרוע סיבוכיות הזמן היא $\\Theta(n\\log k)$.\n\nסיבוכיות המקום של `FindFrequent`, בלי הקריאות הרקורסיביות, היא $\\Theta(1)$. עומק עץ הרקורסיה, כמו שראינו, הוא $\\Theta(\\log k)$, ולכן יש בו $\\Theta(k)$ עלים, כלומר סיבוכיות המקום היא $\\Theta(k)$. $\\square$"
}